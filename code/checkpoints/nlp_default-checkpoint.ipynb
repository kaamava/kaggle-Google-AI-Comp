{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:17:25.740429Z",
     "iopub.status.busy": "2023-10-03T15:17:25.740085Z",
     "iopub.status.idle": "2023-10-03T15:18:09.006390Z",
     "shell.execute_reply": "2023-10-03T15:18:09.005309Z",
     "shell.execute_reply.started": "2023-10-03T15:17:25.740403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_gnn\n",
      "  Downloading tensorflow_gnn-0.6.0-py3-none-any.whl (803 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.9/803.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-vizier>=0.0.13 (from tensorflow_gnn)\n",
      "  Downloading google_vizier-0.1.11-py3-none-any.whl (721 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.6/721.6 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ml-collections (from tensorflow_gnn)\n",
      "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (3.1)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (9.0.0)\n",
      "Requirement already satisfied: apache-beam<2.47.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.46.0)\n",
      "Requirement already satisfied: tensorflow>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.12.0)\n",
      "Requirement already satisfied: protobuf<4,>3.12.2 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.20.3)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.7)\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.9.1)\n",
      "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam<2.47.0->tensorflow_gnn)\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.7.4)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.18)\n",
      "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.51.3)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.7.0)\n",
      "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.21.0)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.23.5)\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.6.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.13.0)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.22.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2023.3)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2023.6.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (4.6.3)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.19.0)\n",
      "Requirement already satisfied: attrs==23.1.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (23.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.4.0)\n",
      "Collecting portpicker>=1.3.1 (from google-vizier>=0.0.13->tensorflow_gnn)\n",
      "  Downloading portpicker-1.6.0-py3-none-any.whl (16 kB)\n",
      "Collecting grpcio-tools>=1.35.0 (from google-vizier>=0.0.13->tensorflow_gnn)\n",
      "  Downloading grpcio_tools-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: googleapis-common-protos>=1.56.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.59.1)\n",
      "Collecting sqlalchemy<=1.4.20,>=1.4 (from google-vizier>=0.0.13->tensorflow_gnn)\n",
      "  Downloading SQLAlchemy-1.4.20.tar.gz (7.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (3.9.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.4.13)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (21.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.32.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml-collections->tensorflow_gnn) (6.0)\n",
      "Collecting contextlib2 (from ml-collections->tensorflow_gnn)\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.10.0->tensorflow_gnn) (0.40.0)\n",
      "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-tools>=1.35.0 (from google-vizier>=0.0.13->tensorflow_gnn)\n",
      "  Downloading grpcio_tools-1.59.0rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.58.0rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.57.0rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.56.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_tools-1.56.0rc2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.55.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.55.0rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.54.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.54.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading grpcio_tools-1.54.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.54.0rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.53.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.53.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.53.0rc2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.52.0rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.51.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.51.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.51.0rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.50.0rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.49.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.49.0rc3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.49.0rc1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading grpcio_tools-1.48.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam<2.47.0->tensorflow_gnn) (0.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.22.0,>=0.8->apache-beam<2.47.0->tensorflow_gnn) (3.0.9)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow>=2.10.0->tensorflow_gnn) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow>=2.10.0->tensorflow_gnn) (1.11.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from portpicker>=1.3.1->google-vizier>=0.0.13->tensorflow_gnn) (5.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<=1.4.20,>=1.4->google-vizier>=0.0.13->tensorflow_gnn) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (2.20.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (3.2.2)\n",
      "Building wheels for collected packages: ml-collections, dill, sqlalchemy\n",
      "  Building wheel for ml-collections (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=7e12725173bc4c8b6807d2e5eb41fd3f72d218aad63e2753f9818f19fb8e410b\n",
      "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78545 sha256=0f0de9808f6c4e490ddd09e1c539ef70281f57fe5404f6716d9cabda880e2dff\n",
      "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
      "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlalchemy: filename=SQLAlchemy-1.4.20-cp310-cp310-linux_x86_64.whl size=1490651 sha256=248df98782c05448f8b3d484ed9891a638c0281bef32fcfffe12345b3e421273\n",
      "  Stored in directory: /root/.cache/pip/wheels/c4/42/20/a958989c470cc1a6fe1d1279b0193f0e508161327fc3d951d9\n",
      "Successfully built ml-collections dill sqlalchemy\n",
      "Installing collected packages: sqlalchemy, portpicker, grpcio-tools, dill, contextlib2, ml-collections, google-vizier, tensorflow_gnn\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.17\n",
      "    Uninstalling SQLAlchemy-2.0.17:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.17\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.7\n",
      "    Uninstalling dill-0.3.7:\n",
      "      Successfully uninstalled dill-0.3.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.20 which is incompatible.\n",
      "multiprocess 0.70.15 requires dill>=0.3.7, but you have dill 0.3.1.1 which is incompatible.\n",
      "pathos 0.3.1 requires dill>=0.3.7, but you have dill 0.3.1.1 which is incompatible.\n",
      "pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\n",
      "pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed contextlib2-21.6.0 dill-0.3.1.1 google-vizier-0.1.11 grpcio-tools-1.48.2 ml-collections-0.1.1 portpicker-1.6.0 sqlalchemy-1.4.20 tensorflow_gnn-0.6.0\n",
      "Collecting tensorflow_ranking\n",
      "  Downloading tensorflow_ranking-0.5.3-py2.py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.2/151.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow_ranking) (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow_ranking) (1.23.5)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_ranking) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-serving-api<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_ranking) (2.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.51.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.20.3)\n",
      "Requirement already satisfied: tensorflow<3,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.12.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.9.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.4.13)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (21.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (68.0.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (4.6.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.11.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.20.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.3.7)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.26.15)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3,>=2.12.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.2.2)\n",
      "Installing collected packages: tensorflow_ranking\n",
      "Successfully installed tensorflow_ranking-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_gnn --pre\n",
    "!pip install tensorflow_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:18:09.009357Z",
     "iopub.status.busy": "2023-10-03T15:18:09.008312Z",
     "iopub.status.idle": "2023-10-03T15:18:18.308566Z",
     "shell.execute_reply": "2023-10-03T15:18:18.307467Z",
     "shell.execute_reply.started": "2023-10-03T15:18:09.009326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install standard modules\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_gnn as tfgnn\n",
    "import tensorflow_ranking as tfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utility modules are based on the code on [github](): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:18:18.310430Z",
     "iopub.status.busy": "2023-10-03T15:18:18.309836Z",
     "iopub.status.idle": "2023-10-03T15:18:50.505912Z",
     "shell.execute_reply": "2023-10-03T15:18:50.504499Z",
     "shell.execute_reply.started": "2023-10-03T15:18:18.310400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_gnn in /opt/conda/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: google-vizier>=0.0.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (0.1.11)\n",
      "Requirement already satisfied: ml-collections in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (0.1.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (3.1)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (9.0.0)\n",
      "Requirement already satisfied: apache-beam<2.47.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.46.0)\n",
      "Requirement already satisfied: tensorflow>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.12.0)\n",
      "Requirement already satisfied: protobuf<4,>3.12.2 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.20.3)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.7)\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.9.1)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.7.4)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.18)\n",
      "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.51.3)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.7.0)\n",
      "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.21.0)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.23.5)\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.6.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.13.0)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.22.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2023.3)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2023.6.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (4.6.3)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.19.0)\n",
      "Requirement already satisfied: attrs==23.1.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (23.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.4.0)\n",
      "Requirement already satisfied: portpicker>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.6.0)\n",
      "Requirement already satisfied: grpcio-tools>=1.35.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.48.2)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.56.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.59.1)\n",
      "Requirement already satisfied: sqlalchemy<=1.4.20,>=1.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.4.20)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (3.9.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.4.13)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (21.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.32.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml-collections->tensorflow_gnn) (6.0)\n",
      "Requirement already satisfied: contextlib2 in /opt/conda/lib/python3.10/site-packages (from ml-collections->tensorflow_gnn) (21.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.10.0->tensorflow_gnn) (0.40.0)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam<2.47.0->tensorflow_gnn) (0.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.22.0,>=0.8->apache-beam<2.47.0->tensorflow_gnn) (3.0.9)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow>=2.10.0->tensorflow_gnn) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow>=2.10.0->tensorflow_gnn) (1.11.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from portpicker>=1.3.1->google-vizier>=0.0.13->tensorflow_gnn) (5.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<=1.4.20,>=1.4->google-vizier>=0.0.13->tensorflow_gnn) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (2.20.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (3.2.2)\n",
      "Requirement already satisfied: tensorflow_gnn in /opt/conda/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: google-vizier>=0.0.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (0.1.11)\n",
      "Requirement already satisfied: ml-collections in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (0.1.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (3.1)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (9.0.0)\n",
      "Requirement already satisfied: apache-beam<2.47.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.46.0)\n",
      "Requirement already satisfied: tensorflow>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.12.0)\n",
      "Requirement already satisfied: protobuf<4,>3.12.2 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.20.3)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.7)\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.9.1)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.7.4)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.18)\n",
      "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.51.3)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.7.0)\n",
      "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.21.0)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.23.5)\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.6.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.13.0)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.22.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2023.3)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2023.6.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (4.6.3)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.19.0)\n",
      "Requirement already satisfied: attrs==23.1.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (23.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.4.0)\n",
      "Requirement already satisfied: portpicker>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.6.0)\n",
      "Requirement already satisfied: grpcio-tools>=1.35.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.48.2)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.56.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.59.1)\n",
      "Requirement already satisfied: sqlalchemy<=1.4.20,>=1.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.4.20)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (3.9.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.4.13)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (21.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.32.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml-collections->tensorflow_gnn) (6.0)\n",
      "Requirement already satisfied: contextlib2 in /opt/conda/lib/python3.10/site-packages (from ml-collections->tensorflow_gnn) (21.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.10.0->tensorflow_gnn) (0.40.0)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam<2.47.0->tensorflow_gnn) (0.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.22.0,>=0.8->apache-beam<2.47.0->tensorflow_gnn) (3.0.9)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow>=2.10.0->tensorflow_gnn) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow>=2.10.0->tensorflow_gnn) (1.11.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from portpicker>=1.3.1->google-vizier>=0.0.13->tensorflow_gnn) (5.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<=1.4.20,>=1.4->google-vizier>=0.0.13->tensorflow_gnn) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (2.20.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (3.2.2)\n",
      "Requirement already satisfied: tensorflow_gnn in /opt/conda/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: google-vizier>=0.0.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (0.1.11)\n",
      "Requirement already satisfied: ml-collections in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (0.1.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (3.1)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (9.0.0)\n",
      "Requirement already satisfied: apache-beam<2.47.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.46.0)\n",
      "Requirement already satisfied: tensorflow>=2.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow_gnn) (2.12.0)\n",
      "Requirement already satisfied: protobuf<4,>3.12.2 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.20.3)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.7)\n",
      "Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.9.1)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.7.4)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.18)\n",
      "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.51.3)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.7.0)\n",
      "Requirement already satisfied: httplib2<0.22.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.21.0)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.23.5)\n",
      "Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.6.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (3.13.0)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.22.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2023.3)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2023.6.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (4.6.3)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<2.47.0->tensorflow_gnn) (0.19.0)\n",
      "Requirement already satisfied: attrs==23.1.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (23.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.4.0)\n",
      "Requirement already satisfied: portpicker>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.6.0)\n",
      "Requirement already satisfied: grpcio-tools>=1.35.0 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.48.2)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.56.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.59.1)\n",
      "Requirement already satisfied: sqlalchemy<=1.4.20,>=1.4 in /opt/conda/lib/python3.10/site-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.4.20)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (3.9.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.4.13)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (21.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (2.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.10.0->tensorflow_gnn) (0.32.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from ml-collections->tensorflow_gnn) (6.0)\n",
      "Requirement already satisfied: contextlib2 in /opt/conda/lib/python3.10/site-packages (from ml-collections->tensorflow_gnn) (21.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.10.0->tensorflow_gnn) (0.40.0)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam<2.47.0->tensorflow_gnn) (0.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.22.0,>=0.8->apache-beam<2.47.0->tensorflow_gnn) (3.0.9)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow>=2.10.0->tensorflow_gnn) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow>=2.10.0->tensorflow_gnn) (1.11.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from portpicker>=1.3.1->google-vizier>=0.0.13->tensorflow_gnn) (5.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam<2.47.0->tensorflow_gnn) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<=1.4.20,>=1.4->google-vizier>=0.0.13->tensorflow_gnn) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (2.20.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.10.0->tensorflow_gnn) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# Install utility modules.\n",
    "\n",
    "import tpugraphsv1_layout_data_py as layout_data\n",
    "import tpugraphsv1_tile_data_py as tile_data\n",
    "import tpugraphsv1_implicit_py as implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipelines\n",
    "\n",
    "The following code is organized as:\n",
    "\n",
    " 1. Helper functions: MLP (`_mlp`) and Embedding layer (`_Opembedding`). The embedding layer amends a feature on the `op` nodes, with name `op_e`, by embedding the integral op IDs.\n",
    " 1. Pipeline code for training on the Layout collections.\n",
    " 1. Pipeline code for training on the Tile collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions, for both Layout and Tile collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:18:50.508945Z",
     "iopub.status.busy": "2023-10-03T15:18:50.508611Z",
     "iopub.status.idle": "2023-10-03T15:18:50.523111Z",
     "shell.execute_reply": "2023-10-03T15:18:50.521590Z",
     "shell.execute_reply.started": "2023-10-03T15:18:50.508916Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def _mlp(dims, hidden_activation, l2reg=1e-4, use_bias=True):\n",
    "  \"\"\"Helper function for multi-layer perceptron (MLP).\"\"\"\n",
    "  layers = []\n",
    "  for i, dim in enumerate(dims):\n",
    "    if i > 0:\n",
    "      layers.append(tf.keras.layers.Activation(hidden_activation))\n",
    "    layers.append(tf.keras.layers.Dense(\n",
    "        dim, kernel_regularizer=tf.keras.regularizers.l2(l2reg),\n",
    "        use_bias=use_bias))\n",
    "  return tf.keras.Sequential(layers)\n",
    "\n",
    "\n",
    "class _OpEmbedding(tf.keras.Model):\n",
    "  \"\"\"Embeds GraphTensor.node_sets['op']['op'] nodes into feature 'op_e'.\"\"\"\n",
    "\n",
    "  def __init__(self, num_ops: int, embed_d: int, l2reg: float = 1e-4):\n",
    "    super().__init__()\n",
    "    self.embedding_layer = tf.keras.layers.Embedding(\n",
    "        num_ops, embed_d, activity_regularizer=tf.keras.regularizers.l2(l2reg))\n",
    "\n",
    "  def call(\n",
    "      self, graph: tfgnn.GraphTensor,\n",
    "      training: bool = False) -> tfgnn.GraphTensor:\n",
    "    op_features = dict(graph.node_sets['op'].features)\n",
    "    op_features['op_e'] = self.embedding_layer(\n",
    "        tf.cast(graph.node_sets['op']['op'], tf.int32))\n",
    "    return graph.replace_features(node_sets={'op': op_features})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layout Training Pipeline\n",
    "\n",
    "We start by defining constants:\n",
    "\n",
    "1. Batch sizes = num graphs, num sampled nodes per graph, and num configurations per graph.\n",
    "1. Collection to train on: source (`xla` versus `nlp`) and search stragey (`random` versus `default`).\n",
    "\n",
    "Then, boilerplate code to prepare the datasets.\n",
    "\n",
    "Then, we dive deeper into the dataset examples (a batch of graphs from the tiles collection).\n",
    "\n",
    "Finally, details on defining a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants and choose subcollection\n",
    "\n",
    "We load `BATCH_SIZE` graphs per batch. Each will have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:18:50.524947Z",
     "iopub.status.busy": "2023-10-03T15:18:50.524544Z",
     "iopub.status.idle": "2023-10-03T15:18:50.538536Z",
     "shell.execute_reply": "2023-10-03T15:18:50.537255Z",
     "shell.execute_reply.started": "2023-10-03T15:18:50.524909Z"
    }
   },
   "outputs": [],
   "source": [
    "LAYOUT_DATA_ROOT = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout'\n",
    "SOURCE = 'nlp'  # Can be \"xla\" or \"nlp\"\n",
    "SEARCH = 'default'  # Can be \"random\" or \"default\"\n",
    "\n",
    "# Batch size information.\n",
    "BATCH_SIZE = 16  # Number of graphs per batch.\n",
    "CONFIGS_PER_GRAPH = 5  # Number of configurations (features and target values) per graph.\n",
    "MAX_KEEP_NODES = 1000  # Useful for dropout.\n",
    "# `MAX_KEEP_NODES` is (or, is not) useful for Segment Dropout, if model uses\n",
    "# edges \"sampled_config\" and \"sampled_feed\" (or, \"config\" and \"feed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare `tf.data.Dataset` instances\n",
    "Specifically, `layout_train_ds` and `layout_valid_ds`.\n",
    "\n",
    "It can take ~10 minutes if you are running for the first time, for the caches to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:18:50.541076Z",
     "iopub.status.busy": "2023-10-03T15:18:50.540629Z",
     "iopub.status.idle": "2023-10-03T15:20:51.210585Z",
     "shell.execute_reply": "2023-10-03T15:20:51.209234Z",
     "shell.execute_reply.started": "2023-10-03T15:18:50.541036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset cache file:  cache/317e146d60640edb255d1dcb2d3235c8-cache.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:03<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ...\n",
      "wrote cache/317e146d60640edb255d1dcb2d3235c8-cache.npz\n",
      "wrote cache/317e146d60640edb255d1dcb2d3235c8-cache.npz.graphs.txt\n",
      "dataset cache file:  cache/ed1b35ba5a151cd92dc0e4d41f4160ce-cache.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:07<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ...\n",
      "wrote cache/ed1b35ba5a151cd92dc0e4d41f4160ce-cache.npz\n",
      "wrote cache/ed1b35ba5a151cd92dc0e4d41f4160ce-cache.npz.graphs.txt\n",
      "dataset cache file:  cache/437403654dcd7a1b5d98d25edfb15ce6-cache.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ...\n",
      "wrote cache/437403654dcd7a1b5d98d25edfb15ce6-cache.npz\n",
      "wrote cache/437403654dcd7a1b5d98d25edfb15ce6-cache.npz.graphs.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "layout_data_root_dir = os.path.join(\n",
    "      os.path.expanduser(LAYOUT_DATA_ROOT), SOURCE, SEARCH)\n",
    "\n",
    "layout_npz_dataset = layout_data.get_npz_dataset(\n",
    "    layout_data_root_dir,\n",
    "    min_train_configs=CONFIGS_PER_GRAPH,\n",
    "    max_train_configs=500,  # If any graph has more than this configurations, it will be filtered [speeds up loading + training]\n",
    "    cache_dir='cache'\n",
    ")\n",
    "\n",
    "def pair_layout_graph_with_label(graph: tfgnn.GraphTensor):\n",
    "    \"\"\"Extracts label from graph (`tfgnn.GraphTensor`) and returns a pair of `(graph, label)`\"\"\"\n",
    "    # Return runtimes divded over large number: only ranking is required. The\n",
    "    # runtimes are in the 100K range\n",
    "    label = tf.cast(graph.node_sets['g']['runtimes'], tf.float32) / 1e7\n",
    "    return graph, label\n",
    "\n",
    "layout_train_ds = (\n",
    "      layout_npz_dataset.train.get_graph_tensors_dataset(\n",
    "          CONFIGS_PER_GRAPH, max_nodes=MAX_KEEP_NODES)\n",
    "      .shuffle(100, reshuffle_each_iteration=True)\n",
    "      .batch(BATCH_SIZE, drop_remainder=False)\n",
    "      .map(tfgnn.GraphTensor.merge_batch_to_components)\n",
    "      .map(pair_layout_graph_with_label))\n",
    "\n",
    "layout_valid_ds = (\n",
    "      layout_npz_dataset.validation.get_graph_tensors_dataset(\n",
    "          CONFIGS_PER_GRAPH)\n",
    "      .batch(BATCH_SIZE, drop_remainder=False)\n",
    "      .map(tfgnn.GraphTensor.merge_batch_to_components)\n",
    "      .map(pair_layout_graph_with_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Familiarize yourself with data\n",
    "\n",
    "Lets obtain an example from the dataset `layout_train_ds`, i.e., an instance of `GraphTensor` which encodes a batch\n",
    "of graphs. Luckily, using TF-GNN, we can describe our model as-if we are operating on a single graph, and naturally the\n",
    "model extends to multiple graphs!\n",
    "\n",
    "Let's take one example (containing a batch) and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:20:51.212425Z",
     "iopub.status.busy": "2023-10-03T15:20:51.212106Z",
     "iopub.status.idle": "2023-10-03T15:20:54.991191Z",
     "shell.execute_reply": "2023-10-03T15:20:54.990139Z",
     "shell.execute_reply.started": "2023-10-03T15:20:51.212398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_batch = \n",
      "GraphTensor(\n",
      "  context=Context(features={}, sizes=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], shape=(), indices_dtype=tf.int32),\n",
      "  node_set_names=['op', 'nconfig', 'g'],\n",
      "  edge_set_names=['config', 'feed', 'g_op', 'g_config', 'sampled_config', 'sampled_feed'])\n",
      "\n",
      "\n",
      "\n",
      "config_runtimes=\n",
      "tf.Tensor(\n",
      "[[7.96200657e+00 7.96305418e+00 7.96282148e+00 4.35274544e+01\n",
      "  5.35930176e+01]\n",
      " [5.08502913e+00 1.13514872e+01 5.07290459e+00 1.13612328e+01\n",
      "  1.07863512e+01]\n",
      " [2.40560246e+00 3.78197169e+00 3.78209829e+00 2.34496474e+00\n",
      "  1.46323419e+00]\n",
      " [1.93860741e+01 1.64386845e+01 2.00130215e+01 3.15018433e+02\n",
      "  4.73870354e+01]\n",
      " [4.61353455e+01 4.61382828e+01 4.61340752e+01 4.61386414e+01\n",
      "  4.61397858e+01]\n",
      " [6.05140209e-01 7.00804377e+00 6.48077786e-01 6.05187476e-01\n",
      "  6.04645073e-01]\n",
      " [1.65563095e+02 1.65525650e+02 1.85080902e+02 2.79869537e+02\n",
      "  2.79075714e+02]\n",
      " [6.40903187e+00 8.65508652e+00 6.35403633e+00 8.55064297e+00\n",
      "  6.34599400e+00]\n",
      " [1.70146558e+03 1.52145300e+03 1.58357690e+03 1.52178052e+03\n",
      "  1.70174048e+03]\n",
      " [5.07175207e+00 5.07575607e+00 1.13825245e+01 5.06816149e+00\n",
      "  5.07394600e+00]\n",
      " [2.45757847e+01 1.82207909e+01 3.77362404e+01 3.30645943e+01\n",
      "  2.34327965e+01]\n",
      " [1.03269753e+02 3.84730415e+01 8.28444595e+01 5.64325104e+01\n",
      "  3.40058289e+01]\n",
      " [1.90575058e+02 1.90569565e+02 1.90455399e+02 3.83397179e+01\n",
      "  3.83405724e+01]\n",
      " [9.30769424e+01 3.15158920e+01 4.82553040e+02 6.50368118e+01\n",
      "  4.45805130e+01]\n",
      " [1.07740875e+02 1.32914978e+02 1.07456856e+02 1.94075073e+02\n",
      "  1.07901558e+02]\n",
      " [1.03116150e+03 7.55687500e+02 1.28746204e+03 6.91354004e+02\n",
      "  1.30410449e+03]], shape=(16, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "graph_batch, config_runtimes = next(iter(layout_train_ds.take(1)))\n",
    "\n",
    "print('graph_batch = ')\n",
    "print(graph_batch)\n",
    "print('\\n\\n')\n",
    "print('config_runtimes=')\n",
    "print(config_runtimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**< Crash-course on TF-GNN >**\n",
    "\n",
    "Each `GraphTensor` contains three fields:\n",
    "\n",
    "1. `node_sets`, can be thought of `dict` from node type (str) in the graph (batch) to feature tensors for that node type.\n",
    "1. `edge_sets`, can be thought of `dict` from edge type (str) in the graph (batch) to adjacency, as two integer vectors: source IDs and target IDs -- i.e., all edges are directed, unless explicitly undirected by the model. If edge set `e` connects from node-set `n1` to node-set `n2`, then if `graph.edge_sets[\"e1\"].adjacency.source = [0, 13, ...]` and `graph.edge_sets[\"e1\"].adjacency.target = [1, 14, ...]` (must be of equal length), then node `0` from node-set `n1` points to node `1` from node-set `n2`. The IDs are zero-based, and used to index into the feature tensors at `graph.node_sets[\"n1\"]` and `graph.node_sets[\"n2\"]`.\n",
    "1. `context`, contains information per graph in the batch. We do not use this, for the layout collection, as we have singleton nodeset per graph with name `\"g\"` (with features accessible as `graph.node_sets[\"g\"]`)\n",
    "\n",
    "**</ Crash-course on TF-GNN >**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets print the node-sets and the edge-sets of the example `graph_batch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:20:54.993028Z",
     "iopub.status.busy": "2023-10-03T15:20:54.992651Z",
     "iopub.status.idle": "2023-10-03T15:20:55.004804Z",
     "shell.execute_reply": "2023-10-03T15:20:55.003673Z",
     "shell.execute_reply.started": "2023-10-03T15:20:54.992983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_batch.context = Context(features={}, sizes=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], shape=(), indices_dtype=tf.int32)\n",
      "\n",
      "\n",
      " #####  NODE SET \"g\" #########\n",
      "** Has sizes:  tf.Tensor([1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], shape=(16,), dtype=int32)\n",
      "\n",
      " Feature \"graph_id\" has values\n",
      "tf.Tensor(\n",
      "[b'alexnet_train_batch_32' b'transformer.4x4.fp16' b'magenta_dynamic'\n",
      " b'retinanet.2x2.fp32' b'openai_v0_rnn_optimized'\n",
      " b'inference_mlperf_resnet_batch_16' b'resnet_v2_50_batch_128'\n",
      " b'bert_pretraining.8x8.fp32.performance'\n",
      " b'inference_mlperf_ssd_1200_batch_128' b'transformer.2x2.fp32'\n",
      " b'transformer.4x4.bf16' b'mask_rcnn_resnet50.4x4.bf16.performance'\n",
      " b'resnet_v1_50_official_batch_32_bf16'\n",
      " b'mlperf_ssd_1_shard_batch_8_fast_epoch' b'inception_v2_batch_128_train'\n",
      " b'mask_rcnn_batch_4_bf16_img1408'], shape=(16,), dtype=string)\n",
      "\n",
      " Feature \"runtimes\" has values\n",
      "tf.Tensor(\n",
      "[[   79620061    79630540    79628214   435274547   535930184]\n",
      " [   50850291   113514874    50729045   113612327   107863511]\n",
      " [   24056025    37819715    37820985    23449648    14632342]\n",
      " [  193860732   164386845   200130212  3150184448   473870350]\n",
      " [  461353465   461382828   461340764   461386398   461397851]\n",
      " [    6051402    70080437     6480778     6051875     6046451]\n",
      " [ 1655630970  1655256484  1850809000  2798695417  2790757205]\n",
      " [   64090321    86550868    63540364    85506434    63459941]\n",
      " [17014655889 15214529254 15835768642 15217805822 17017404165]\n",
      " [   50717520    50757562   113825252    50681615    50739459]\n",
      " [  245757859   182207907   377362400   330645968   234327967]\n",
      " [ 1032697547   384730415   828444617   564325127   340058320]\n",
      " [ 1905750672  1905695617  1904554025   383397191   383405740]\n",
      " [  930769381   315158898  4825530404   650368128   445805132]\n",
      " [ 1077408708  1329149775  1074568548  1940750747  1079015501]\n",
      " [10311615287  7556875341 12874621127  6913540012 13041044805]], shape=(16, 5), dtype=int64)\n",
      "\n",
      " Feature \"kept_node_ratio\" has values\n",
      "tf.Tensor(\n",
      "[1.         0.04423812 1.         0.07211365 0.21691464 0.90009004\n",
      " 0.19372337 0.04733504 0.04033885 0.13653742 0.03716643 0.06350013\n",
      " 0.16297261 0.06681598 0.11317338 0.07958616], shape=(16,), dtype=float32)\n",
      "\n",
      "\n",
      " #####  NODE SET \"nconfig\" #########\n",
      "** Has sizes:  tf.Tensor(\n",
      "[  26  414   58  351   62   55  162 1164 2002  414 1770 1250  166  374\n",
      "  216  583], shape=(16,), dtype=int32)\n",
      "\n",
      " Feature \"feats\" has values\n",
      "tf.Tensor(\n",
      "[[[0.6666667  0.16666667 0.         ... 0.         0.8        0.6       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.8        0.6       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.8        0.6       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.6        0.8       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.6        0.8       ]]\n",
      "\n",
      " [[0.6666667  0.16666667 0.         ... 0.         0.8        0.6       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.8        0.6       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.8        0.6       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.6        0.8       ]\n",
      "  [0.16666667 0.6666667  0.         ... 0.         0.8        0.6       ]]\n",
      "\n",
      " [[0.6666667  0.16666667 0.         ... 0.         0.8        0.6       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.8        0.6       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.8        0.6       ]\n",
      "  [0.6666667  0.16666667 0.         ... 0.         0.6        0.8       ]\n",
      "  [0.16666667 0.6666667  0.         ... 0.         0.8        0.6       ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.33333334 0.16666667 0.         ... 0.         0.         0.        ]\n",
      "  [0.16666667 0.33333334 0.         ... 0.         0.         0.        ]\n",
      "  [0.33333334 0.16666667 0.         ... 0.         0.         0.        ]\n",
      "  [0.33333334 0.16666667 0.         ... 0.         0.         0.        ]\n",
      "  [0.16666667 0.33333334 0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.33333334 0.16666667 0.         ... 0.         0.4        0.2       ]\n",
      "  [0.33333334 0.16666667 0.         ... 0.         0.4        0.2       ]\n",
      "  [0.33333334 0.16666667 0.         ... 0.         0.         0.        ]\n",
      "  [0.33333334 0.16666667 0.         ... 0.         0.4        0.2       ]\n",
      "  [0.33333334 0.16666667 0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.16666667 0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.16666667 0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.16666667 0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.16666667 0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.16666667 0.         0.         ... 0.         0.         0.        ]]], shape=(9067, 5, 14), dtype=float32)\n",
      "\n",
      "\n",
      " #####  NODE SET \"op\" #########\n",
      "** Has sizes:  tf.Tensor(\n",
      "[  372  7324   650 13867  1277  1111  5162 21126 24790  7324 26906 15748\n",
      "  6136  5358  8836 12565], shape=(16,), dtype=int32)\n",
      "\n",
      " Feature \"op\" has values\n",
      "tf.Tensor([ 63  63  57 ...  45  45 100], shape=(158552,), dtype=uint8)\n",
      "\n",
      " Feature \"feats\" has values\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [1.  0.  0.  ... 0.  0.  0. ]\n",
      " ...\n",
      " [0.  0.  0.  ... 0.2 0.  0. ]\n",
      " [0.  0.  0.  ... 0.2 0.  0. ]\n",
      " [1.  0.  0.  ... 0.  0.  0. ]], shape=(158552, 112), dtype=float32)\n",
      "\n",
      " Feature \"selected\" has values\n",
      "tf.Tensor([ True  True  True ... False False False], shape=(158552,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# The `graph_batch` contains node-sets and edge-sets.\n",
    "# There are no context features for layout collection\n",
    "print('graph_batch.context =', graph_batch.context)\n",
    "# Note: graph_batch.context.sizes must be equal to BATCH_SIZE.\n",
    "# Lets print-out all features for all nodesets.\n",
    "\n",
    "for node_set_name in sorted(graph_batch.node_sets.keys()):\n",
    "    print(f'\\n\\n #####  NODE SET \"{node_set_name}\" #########')\n",
    "    print('** Has sizes: ', graph_batch.node_sets[node_set_name].sizes)\n",
    "    for feature_name in graph_batch.node_sets[node_set_name].features.keys():\n",
    "        print(f'\\n Feature \"{feature_name}\" has values')\n",
    "        print(graph_batch.node_sets[node_set_name][feature_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The node set `'g'` corresponds to the \"graph-level\"**. Since `BATCH_SIZE==16`, each tensor in `'g'` should have a leading dimension of `16`. The `graph_id` feature contains model names. Since `CONFIGS_PER_GRAPH_PER_EPOCH=5`, then feature 'runtimes' must be of shape `(16, 5)` with `graph_batch.node_sets['g']['runtimes'][i, j]` indicating the runtime when compiling graph `i` with configuration features `j`. These specific feature values must be found in `nconfig` node-set, as explained next.\n",
    "\n",
    "**Lets look at nodes per graph**. For instance, node set `op` contains the operation nodes in the tensorflow graph (e.g., element-wise add, matrix multiply, etc). Op-codes are stored in `graph_batch.node_sets['op']['op']`. Since each graph has variable number of nodes, the array `graph_batch.node_sets['op'].sizes` gives the number of `op` nodes per (of the `16`) graphs.\n",
    "\n",
    "Some nodes are configurable. The (*virtual*) node-set `nconfig` contains features for configurable nodes. The features are in `graph_batch.node_sets['nconfig']['feats']`.\n",
    "\n",
    "\n",
    "The edge-set `'config'` (next) indicates the correspondence between `nconfig` features and `op` nodes. Specifically, each (*virtual*) `config` node has degree of 1 and each `op` node has degree of 0 or 1 (on edge-set `'config'`).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print-out all the edge-sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:20:55.006956Z",
     "iopub.status.busy": "2023-10-03T15:20:55.006545Z",
     "iopub.status.idle": "2023-10-03T15:20:55.022121Z",
     "shell.execute_reply": "2023-10-03T15:20:55.020919Z",
     "shell.execute_reply.started": "2023-10-03T15:20:55.006916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " config edge set:  EdgeSet(features={}, sizes=[  26  414   58  351   62   55  162 1164 2002  414 1770 1250  166  374\n",
      "  216  583], adjacency=Adjacency(source=('nconfig', <tf.Tensor: shape=(9067,), dtype=tf.int32>), target=('op', <tf.Tensor: shape=(9067,), dtype=tf.int32>)))\n",
      "\n",
      " config source nodes:  tf.Tensor([   0    1    2 ... 9064 9065 9066], shape=(9067,), dtype=int32)\n",
      "\n",
      " config target nodes:  tf.Tensor([    86     95    103 ... 154940 154941 156246], shape=(9067,), dtype=int32)\n",
      "\n",
      " g_op edge set:  EdgeSet(features={}, sizes=[  372  7324   650 13867  1277  1111  5162 21126 24790  7324 26906 15748\n",
      "  6136  5358  8836 12565], adjacency=Adjacency(source=('g', <tf.Tensor: shape=(158552,), dtype=tf.int32>), target=('op', <tf.Tensor: shape=(158552,), dtype=tf.int32>)))\n",
      "\n",
      " g_config edge set:  EdgeSet(features={}, sizes=[  26  414   58  351   62   55  162 1164 2002  414 1770 1250  166  374\n",
      "  216  583], adjacency=Adjacency(source=('g', <tf.Tensor: shape=(9067,), dtype=tf.int32>), target=('nconfig', <tf.Tensor: shape=(9067,), dtype=tf.int32>)))\n"
     ]
    }
   ],
   "source": [
    "print('\\n config edge set: ', graph_batch.edge_sets['config'])  \n",
    "print('\\n config source nodes: ', graph_batch.edge_sets['config'].adjacency.source)\n",
    "print('\\n config target nodes: ', graph_batch.edge_sets['config'].adjacency.target)\n",
    "print('\\n g_op edge set: ', graph_batch.edge_sets['g_op'])\n",
    "print('\\n g_config edge set: ', graph_batch.edge_sets['g_config'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edge-set `'config'` pairs each `\"nconfig\"` node with one `\"op\"` node. To list the correspondences, you print the `.adjacency.source` and `.adjacency.target`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:20:55.027021Z",
     "iopub.status.busy": "2023-10-03T15:20:55.026653Z",
     "iopub.status.idle": "2023-10-03T15:20:55.036174Z",
     "shell.execute_reply": "2023-10-03T15:20:55.035155Z",
     "shell.execute_reply.started": "2023-10-03T15:20:55.026991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdgeSet(features={}, sizes=[  26  414   58  351   62   55  162 1164 2002  414 1770 1250  166  374\n",
      "  216  583], adjacency=Adjacency(source=('nconfig', <tf.Tensor: shape=(9067,), dtype=tf.int32>), target=('op', <tf.Tensor: shape=(9067,), dtype=tf.int32>)))\n",
      "tf.Tensor([   0    1    2 ... 9064 9065 9066], shape=(9067,), dtype=int32)\n",
      "tf.Tensor([    86     95    103 ... 154940 154941 156246], shape=(9067,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(graph_batch.edge_sets['config'])   # Holds directed adjacency as list of pairs of indices: nconfig->op\n",
    "print(graph_batch.edge_sets['config'].adjacency.source)  # Print nconfig indices (should be a range())\n",
    "print(graph_batch.edge_sets['config'].adjacency.target)  # Print corresponding `op` indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than `config` edges, the remainder of the edge-sets are:\n",
    "```\n",
    "'feed', 'g_op', 'g_config', 'sampled_config', 'sampled_feed'\n",
    "```\n",
    "\n",
    "The first (`feed`) is the actual computation graph! `op` nodes feed into `op` nodes. **Note: The \"transpose\" of this adjacency (implicit) matrix indicates the direction of information flow (models are later in the tutorial).**. The second (`g_op`) and third (`g_config`), group by graph, respectively, `op` nodes and the (virtual) `nconfig` nodes. This edge-set can be helpful for global-pooling operations. \n",
    "\n",
    "*Segment-level Training*: Finally, to implement some version of **dropout**, `sampled_config` and `sampled_feed` edge-sets contain edges to randomly-sampled `op` nodes. To do full-graph (training or inference), you may use `config` and `feed`. To do training with segment dropout (e.g., a naive version of https://arxiv.org/abs/2308.13490, to appear @ NeurIPS'23), you may use `sampled_config` and `sampled_feed`. You may adjust the number of **keep** nodes by setting `MAX_KEEP_NODES`. An edge only survives in `sampled_feed` only if both of its endpoints survived (segment-level) dropout. In our naive implementation here, nodes with contiguous indices are kept. However, you are welcome to re-implement a better segmentation strategy.\n",
    "\n",
    "\n",
    "*NOTE: When using TF-GNN (models to follow), you dont have to worry about `sizes`: just write your model code as-if you are operating on a single graph, and the code naturally extends to a batch of graphs.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Before we define the full model (`ResModel`), lets run some modeling functions. For example, let's embed the op-codes.\n",
    "\n",
    "We have `layout_npz_dataset.num_ops` unique number of op codes, which determines the embedding size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:20:55.037609Z",
     "iopub.status.busy": "2023-10-03T15:20:55.037291Z",
     "iopub.status.idle": "2023-10-03T15:20:55.113632Z",
     "shell.execute_reply": "2023-10-03T15:20:55.112331Z",
     "shell.execute_reply.started": "2023-10-03T15:20:55.037582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of ops in the dataset= 119\n",
      "\n",
      "\n",
      " Before embedding, node-set \"op\"=\n",
      " NodeSet(features={'op': <tf.Tensor: shape=(158552,), dtype=tf.uint8>, 'feats': <tf.Tensor: shape=(158552, 112), dtype=tf.float32>, 'selected': <tf.Tensor: shape=(158552,), dtype=tf.bool>}, sizes=[  372  7324   650 13867  1277  1111  5162 21126 24790  7324 26906 15748\n",
      "  6136  5358  8836 12565])\n",
      "\n",
      "\n",
      " After embedding, node-set \"op\"=\n",
      " NodeSet(features={'op': <tf.Tensor: shape=(158552,), dtype=tf.uint8>, 'feats': <tf.Tensor: shape=(158552, 112), dtype=tf.float32>, 'selected': <tf.Tensor: shape=(158552,), dtype=tf.bool>, 'op_e': <tf.Tensor: shape=(158552, 16), dtype=tf.float32>}, sizes=[  372  7324   650 13867  1277  1111  5162 21126 24790  7324 26906 15748\n",
      "  6136  5358  8836 12565])\n"
     ]
    }
   ],
   "source": [
    "num_ops = layout_npz_dataset.num_ops\n",
    "print('number of ops in the dataset=', num_ops)\n",
    "\n",
    "embedding_layer = _OpEmbedding(num_ops, 16)  # 16-dimensional embedding, for demonstration.\n",
    "graph_batch_embedded_ops = embedding_layer(graph_batch)\n",
    "\n",
    "print('\\n\\n Before embedding, node-set \"op\"=\\n', graph_batch.node_sets['op'])\n",
    "print('\\n\\n After embedding, node-set \"op\"=\\n', graph_batch_embedded_ops.node_sets['op'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: after embedding, an additional feature `\"op_e\"` shows-up.*\n",
    "\n",
    "Now, lets concatenate the configuration features with the embedding features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:20:55.115334Z",
     "iopub.status.busy": "2023-10-03T15:20:55.115027Z",
     "iopub.status.idle": "2023-10-03T15:20:55.122493Z",
     "shell.execute_reply": "2023-10-03T15:20:55.121077Z",
     "shell.execute_reply.started": "2023-10-03T15:20:55.115309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op_e.shape == (158552, 16)\n",
      "config_features.shape == (9067, 5, 14)\n"
     ]
    }
   ],
   "source": [
    "op_e = graph_batch_embedded_ops.node_sets['op']['op_e']\n",
    "config_features = graph_batch_embedded_ops.node_sets['nconfig']['feats']\n",
    "\n",
    "print('op_e.shape ==', op_e.shape)\n",
    "print('config_features.shape ==', config_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two differences in the shapes, yet, we concatenate them.\n",
    "\n",
    "1. `op_e` has more nodes: every node has an op-code, but not every node is configurable. We first to resize the leading dimension of `config_features` to equal the leading dimension of `op_e`, by filling zeros for nodes that are not configurable.\n",
    "1. `config_features` is cuboid. The middle dimension identifies the configuration: there are `CONFIGS_PER_GRAPH` of them.\n",
    "\n",
    "\n",
    "For the first, we can multiply by the (sparse) \"config\" adjacency matrix -- a binary matrix where every is a one-hot and most rows are zero. If adjacency entry at `[i, j]` is set, then `graph.node_sets[\"nconfig\"][\"feats\"][j]`  contain configuration features for node `i` of `graph.node_sets[\"op\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:20:55.124334Z",
     "iopub.status.busy": "2023-10-03T15:20:55.123900Z",
     "iopub.status.idle": "2023-10-03T15:20:55.153467Z",
     "shell.execute_reply": "2023-10-03T15:20:55.152386Z",
     "shell.execute_reply.started": "2023-10-03T15:20:55.124291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config_adj.shape = (<tf.Tensor: shape=(), dtype=int32, numpy=158552>, <tf.Tensor: shape=(), dtype=int32, numpy=9067>)\n",
      "resized_config_features.shape = (158552, 5, 14)\n"
     ]
    }
   ],
   "source": [
    "config_adj = implicit.AdjacencyMultiplier(graph_batch_embedded_ops, 'config')\n",
    "print('config_adj.shape =', config_adj.shape)\n",
    "resized_config_features = config_adj @ config_features\n",
    "print('resized_config_features.shape =', resized_config_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to broadcast the `op_e` feature matrix to a cuboid, by replicating on a (new) inner dimension so that we can finally combine the config features with op-embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:20:55.155272Z",
     "iopub.status.busy": "2023-10-03T15:20:55.154845Z",
     "iopub.status.idle": "2023-10-03T15:20:55.205184Z",
     "shell.execute_reply": "2023-10-03T15:20:55.204051Z",
     "shell.execute_reply.started": "2023-10-03T15:20:55.155240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_features.shape =  (158552, 5, 30)\n"
     ]
    }
   ],
   "source": [
    "broadcasted_op_e = tf.stack([op_e] * CONFIGS_PER_GRAPH, axis=1)\n",
    "\n",
    "combined_features = tf.concat([broadcasted_op_e, resized_config_features], axis=-1)\n",
    "\n",
    "print('combined_features.shape = ', combined_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to do graph convolution layer (i.e., message-passing followed by non-linearity) among the `feed` edges. Usually, this can be done by left-multiplying the feature tensor with **some form** of an adjacency matrix. The exact form will determine the pooling (e.g., sum VS average). Let us use the symmetrically-normalized adjacency matrix with self-connections added (by Kipf & Welling, ICLR'17).\n",
    "\n",
    "We can compute such a matrix $\\widehat{A}$ as:\n",
    "\n",
    "$$A_\\textrm{undirected.w.selfconnections} \\leftarrow A + A^\\top + I$$\n",
    "\n",
    "\n",
    "$$D \\leftarrow \\mathbf{1}^\\top A_\\textrm{undirected.w.selfconnections}$$\n",
    "\n",
    "\n",
    "$$\\widehat{A} \\leftarrow D^{-\\frac{1}{2}} (A_\\textrm{undirected.w.selfconnections}) D^{-\\frac{1}{2}} $$\n",
    "\n",
    "Which is acheivable by the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:20:55.206654Z",
     "iopub.status.busy": "2023-10-03T15:20:55.206265Z",
     "iopub.status.idle": "2023-10-03T15:20:55.288568Z",
     "shell.execute_reply": "2023-10-03T15:20:55.287552Z",
     "shell.execute_reply.started": "2023-10-03T15:20:55.206615Z"
    }
   },
   "outputs": [],
   "source": [
    "adj_op_op = implicit.AdjacencyMultiplier(graph_batch_embedded_ops, 'feed')  # op->op\n",
    "adj_config = implicit.AdjacencyMultiplier(graph_batch_embedded_ops, 'config')  # nconfig->op\n",
    "\n",
    "adj_op_op_hat = (adj_op_op + adj_op_op.transpose()).add_eye()\n",
    "adj_op_op_hat = adj_op_op_hat.normalize_symmetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the message passing can written as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:20:55.290522Z",
     "iopub.status.busy": "2023-10-03T15:20:55.290091Z",
     "iopub.status.idle": "2023-10-03T15:21:00.051943Z",
     "shell.execute_reply": "2023-10-03T15:21:00.050316Z",
     "shell.execute_reply.started": "2023-10-03T15:20:55.290481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_times_x.shape = (158552, 5, 30)\n"
     ]
    }
   ],
   "source": [
    "A_times_X = adj_op_op_hat @ combined_features\n",
    "print('A_times_x.shape =', A_times_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we put together everything above to write a model class `ResModel` (next), which has a couple more concepts:\n",
    "\n",
    "1. Adjacency for `\"g_op\"` and `\"g_config\"`, which is used to pool information from all ops and from configurable ops, to the graph level.\n",
    "1. Residual connections.\n",
    "1. Segment dropout. a forward-pass is computed on the entire graph (but, with `tf.stop_gradient`). Then, another forward pass is computed using only sampled edge-sets (`edgeset_prefix` is set to `\"sampled_\"` by `forward()`).\n",
    "\n",
    "Without further ado, `ResModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:21:00.054944Z",
     "iopub.status.busy": "2023-10-03T15:21:00.054444Z",
     "iopub.status.idle": "2023-10-03T15:21:00.075549Z",
     "shell.execute_reply": "2023-10-03T15:21:00.074267Z",
     "shell.execute_reply.started": "2023-10-03T15:21:00.054902Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResModel(tf.keras.Model):\n",
    "    \"\"\"GNN with residual connections.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, num_configs: int, num_ops: int, op_embed_dim: int = 32,\n",
    "        num_gnns: int = 2, mlp_layers: int = 2,\n",
    "        hidden_activation: str = 'leaky_relu',\n",
    "        hidden_dim: int = 32, reduction: str = 'sum'):\n",
    "        super().__init__()\n",
    "        self._num_configs = num_configs\n",
    "        self._num_ops = num_ops\n",
    "        self._op_embedding = _OpEmbedding(num_ops, op_embed_dim)\n",
    "        self._prenet = _mlp([hidden_dim] * mlp_layers, hidden_activation)\n",
    "        self._gc_layers = []\n",
    "        for _ in range(num_gnns):\n",
    "            self._gc_layers.append(_mlp([hidden_dim] * mlp_layers, hidden_activation))\n",
    "        self._postnet = _mlp([hidden_dim, 1], hidden_activation, use_bias=False)\n",
    "\n",
    "    def call(self, graph: tfgnn.GraphTensor, training: bool = False):\n",
    "        del training\n",
    "        return self.forward(graph, self._num_configs)\n",
    "\n",
    "    def _node_level_forward(\n",
    "        self, node_features: tf.Tensor,\n",
    "        config_features: tf.Tensor,\n",
    "        graph: tfgnn.GraphTensor, num_configs: int,\n",
    "        edgeset_prefix='') -> tf.Tensor:\n",
    "        adj_op_op = implicit.AdjacencyMultiplier(\n",
    "            graph, edgeset_prefix+'feed')  # op->op\n",
    "        adj_config = implicit.AdjacencyMultiplier(\n",
    "            graph, edgeset_prefix+'config')  # nconfig->op\n",
    "\n",
    "        adj_op_op_hat = (adj_op_op + adj_op_op.transpose()).add_eye()\n",
    "        adj_op_op_hat = adj_op_op_hat.normalize_symmetric()\n",
    "\n",
    "        x = node_features\n",
    "\n",
    "        x = tf.stack([x] * num_configs, axis=1)\n",
    "        config_features = 100 * (adj_config @ config_features)\n",
    "        x = tf.concat([config_features, x], axis=-1)\n",
    "        x = self._prenet(x)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        for layer in self._gc_layers:\n",
    "            y = x\n",
    "            y = tf.concat([config_features, y], axis=-1)\n",
    "            y = tf.nn.leaky_relu(layer(adj_op_op_hat @ y))\n",
    "            x += y\n",
    "        return x\n",
    "\n",
    "    def forward(\n",
    "        self, graph: tfgnn.GraphTensor, num_configs: int,\n",
    "        backprop=True) -> tf.Tensor:\n",
    "        graph = self._op_embedding(graph)\n",
    "\n",
    "        config_features = graph.node_sets['nconfig']['feats']\n",
    "        node_features = tf.concat([\n",
    "            graph.node_sets['op']['feats'],\n",
    "            graph.node_sets['op']['op_e']\n",
    "        ], axis=-1)\n",
    "\n",
    "        x_full = self._node_level_forward(\n",
    "            node_features=tf.stop_gradient(node_features),\n",
    "            config_features=tf.stop_gradient(config_features),\n",
    "            graph=graph, num_configs=num_configs)\n",
    "\n",
    "        if backprop:\n",
    "            x_backprop = self._node_level_forward(\n",
    "                node_features=node_features,\n",
    "                config_features=config_features,\n",
    "                graph=graph, num_configs=num_configs, edgeset_prefix='sampled_')\n",
    "\n",
    "            is_selected = graph.node_sets['op']['selected']\n",
    "            # Need to expand twice as `is_selected` is a vector (num_nodes) but\n",
    "            # x_{backprop, full} are 3D tensors (num_nodes, num_configs, num_feats).\n",
    "            is_selected = tf.expand_dims(is_selected, axis=-1)\n",
    "            is_selected = tf.expand_dims(is_selected, axis=-1)\n",
    "            x = tf.where(is_selected, x_backprop, x_full)\n",
    "        else:\n",
    "            x = x_full\n",
    "\n",
    "        adj_config = implicit.AdjacencyMultiplier(graph, 'config')\n",
    "\n",
    "        # Features for configurable nodes.\n",
    "        config_feats = (adj_config.transpose() @ x)\n",
    "\n",
    "        # Global pooling\n",
    "        adj_pool_op_sum = implicit.AdjacencyMultiplier(graph, 'g_op').transpose()\n",
    "        adj_pool_op_mean = adj_pool_op_sum.normalize_right()\n",
    "        adj_pool_config_sum = implicit.AdjacencyMultiplier(\n",
    "            graph, 'g_config').transpose()\n",
    "        x = self._postnet(tf.concat([\n",
    "            # (A D^-1) @ Features\n",
    "            adj_pool_op_mean @ x,\n",
    "            # l2_normalize( A @ Features )\n",
    "            tf.nn.l2_normalize(adj_pool_op_sum @ x, axis=-1),\n",
    "            # l2_normalize( A @ Features )\n",
    "            tf.nn.l2_normalize(adj_pool_config_sum @ config_feats, axis=-1),\n",
    "        ], axis=-1))\n",
    "\n",
    "        x = tf.squeeze(x, -1)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "Create a model, objective function, and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:21:00.077361Z",
     "iopub.status.busy": "2023-10-03T15:21:00.077024Z",
     "iopub.status.idle": "2023-10-03T15:21:00.153661Z",
     "shell.execute_reply": "2023-10-03T15:21:00.152391Z",
     "shell.execute_reply.started": "2023-10-03T15:21:00.077332Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ResModel(CONFIGS_PER_GRAPH, layout_npz_dataset.num_ops)\n",
    "\n",
    "loss = tfr.keras.losses.ListMLELoss()  # (temperature=10)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=0.5)\n",
    "\n",
    "model.compile(loss=loss, optimizer=opt, metrics=[\n",
    "    tfr.keras.metrics.OPAMetric(name='opa_metric'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:21:00.155936Z",
     "iopub.status.busy": "2023-10-03T15:21:00.155331Z",
     "iopub.status.idle": "2023-10-03T15:26:10.320320Z",
     "shell.execute_reply": "2023-10-03T15:26:10.319071Z",
     "shell.execute_reply.started": "2023-10-03T15:21:00.155740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 308s 53s/step - loss: 4.7318 - opa_metric: 0.5449 - val_loss: 4.8636 - val_opa_metric: 0.4714\n",
      " * [@0] Validation (NEW BEST): 0.4714285731315613\n",
      "Restoring parameters corresponding to the best validation OPA.\n"
     ]
    }
   ],
   "source": [
    "early_stop = 5  # If validation OPA did not increase in this many epochs, terminate training.\n",
    "best_params = None  # Stores parameters corresponding to best validation OPA, to restore to them after training.\n",
    "best_val_opa = -1  # Tracks best validation OPA\n",
    "best_val_at_epoch = -1  # At which epoch.\n",
    "epochs = 20  # Total number of training epochs.\n",
    "\n",
    "for i in range(epochs):\n",
    "    history = model.fit(\n",
    "        layout_train_ds, epochs=1, verbose=1, validation_data=layout_valid_ds,\n",
    "        validation_freq=1)\n",
    "\n",
    "    train_loss = history.history['loss'][-1]\n",
    "    train_opa = history.history['opa_metric'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_opa = history.history['val_opa_metric'][-1]\n",
    "    if val_opa > best_val_opa:\n",
    "        best_val_opa = val_opa\n",
    "        best_val_at_epoch = i\n",
    "        best_params = {v.ref: v + 0 for v in model.trainable_variables}\n",
    "        print(' * [@%i] Validation (NEW BEST): %s' % (i, str(val_opa)))\n",
    "    elif early_stop > 0 and i - best_val_at_epoch >= early_stop:\n",
    "      print('[@%i] Best accuracy was attained at epoch %i. Stopping.' % (i, best_val_at_epoch))\n",
    "      break\n",
    "\n",
    "# Restore best parameters.\n",
    "print('Restoring parameters corresponding to the best validation OPA.')\n",
    "assert best_params is not None\n",
    "for v in model.trainable_variables:\n",
    "    v.assign(best_params[v.ref])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Submission CSV file for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T15:26:10.322337Z",
     "iopub.status.busy": "2023-10-03T15:26:10.321540Z",
     "iopub.status.idle": "2023-10-03T16:37:30.828518Z",
     "shell.execute_reply": "2023-10-03T16:37:30.825204Z",
     "shell.execute_reply.started": "2023-10-03T15:26:10.322306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   Running inference on test set ...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:00<00:10,  1.75it/s]\u001b[A\n",
      " 10%|█         | 2/20 [00:00<00:08,  2.18it/s]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:01<00:07,  2.35it/s]\u001b[A\n",
      " 20%|██        | 4/20 [00:01<00:06,  2.45it/s]\u001b[A\n",
      " 25%|██▌       | 5/20 [00:02<00:05,  2.51it/s]\u001b[A\n",
      " 30%|███       | 6/20 [00:02<00:05,  2.54it/s]\u001b[A\n",
      " 35%|███▌      | 7/20 [00:02<00:05,  2.56it/s]\u001b[A\n",
      " 40%|████      | 8/20 [00:03<00:04,  2.58it/s]\u001b[A\n",
      " 45%|████▌     | 9/20 [00:03<00:04,  2.57it/s]\u001b[A\n",
      " 50%|█████     | 10/20 [00:04<00:03,  2.52it/s]\u001b[A\n",
      " 55%|█████▌    | 11/20 [00:04<00:03,  2.55it/s]\u001b[A\n",
      " 60%|██████    | 12/20 [00:04<00:03,  2.58it/s]\u001b[A\n",
      " 65%|██████▌   | 13/20 [00:05<00:02,  2.59it/s]\u001b[A\n",
      " 70%|███████   | 14/20 [00:05<00:02,  2.59it/s]\u001b[A\n",
      " 75%|███████▌  | 15/20 [00:05<00:01,  2.60it/s]\u001b[A\n",
      " 80%|████████  | 16/20 [00:06<00:01,  2.60it/s]\u001b[A\n",
      " 85%|████████▌ | 17/20 [00:06<00:01,  2.37it/s]\u001b[A\n",
      " 90%|█████████ | 18/20 [00:07<00:00,  2.28it/s]\u001b[A\n",
      " 95%|█████████▌| 19/20 [00:07<00:00,  2.20it/s]\u001b[A\n",
      "100%|██████████| 20/20 [00:08<00:00,  2.43it/s]\u001b[A\n",
      "Inference:  12%|█▎        | 1/8 [00:08<01:01,  8.81s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:46<14:49, 46.83s/it]\u001b[A\n",
      " 10%|█         | 2/20 [01:33<13:58, 46.59s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [02:18<13:05, 46.19s/it]\u001b[A\n",
      " 20%|██        | 4/20 [03:04<12:13, 45.84s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [03:50<11:27, 45.82s/it]\u001b[A\n",
      " 30%|███       | 6/20 [04:35<10:41, 45.84s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [05:22<09:59, 46.13s/it]\u001b[A\n",
      " 40%|████      | 8/20 [06:28<10:29, 52.47s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [07:18<09:27, 51.60s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [08:05<08:21, 50.13s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [08:53<07:25, 49.47s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [09:40<06:29, 48.70s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [10:26<05:36, 48.12s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [11:14<04:47, 47.91s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [12:00<03:57, 47.51s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [12:50<03:12, 48.08s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [13:36<02:22, 47.55s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [14:23<01:34, 47.33s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [15:11<00:47, 47.46s/it]\u001b[A\n",
      "100%|██████████| 20/20 [16:00<00:00, 48.00s/it]\u001b[A\n",
      "Inference:  25%|██▌       | 2/8 [16:09<56:52, 568.67s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:26<08:24, 26.54s/it]\u001b[A\n",
      " 10%|█         | 2/20 [01:16<12:04, 40.27s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [01:41<09:30, 33.54s/it]\u001b[A\n",
      " 20%|██        | 4/20 [02:07<08:03, 30.23s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [02:32<07:06, 28.46s/it]\u001b[A\n",
      " 30%|███       | 6/20 [02:57<06:23, 27.38s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [03:23<05:47, 26.70s/it]\u001b[A\n",
      " 40%|████      | 8/20 [03:48<05:16, 26.40s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [04:14<04:48, 26.21s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [04:40<04:21, 26.14s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [05:06<03:55, 26.15s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [05:32<03:27, 25.98s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [05:57<03:00, 25.74s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [06:22<02:33, 25.50s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [06:47<02:06, 25.38s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [07:12<01:40, 25.16s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [07:37<01:15, 25.13s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [08:02<00:50, 25.13s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [08:29<00:25, 25.73s/it]\u001b[A\n",
      "100%|██████████| 20/20 [08:56<00:00, 26.81s/it]\u001b[A\n",
      "Inference:  38%|███▊      | 3/8 [25:06<46:11, 554.20s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:27<08:47, 27.79s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:56<08:28, 28.24s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [01:24<07:58, 28.16s/it]\u001b[A\n",
      " 20%|██        | 4/20 [01:50<07:20, 27.50s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [02:26<07:37, 30.50s/it]\u001b[A\n",
      " 30%|███       | 6/20 [03:11<08:16, 35.43s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [03:38<07:04, 32.66s/it]\u001b[A\n",
      " 40%|████      | 8/20 [04:06<06:12, 31.05s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [04:33<05:28, 29.90s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [05:01<04:51, 29.16s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [05:29<04:19, 28.78s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [05:57<03:49, 28.63s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [06:25<03:18, 28.34s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [06:51<02:47, 27.85s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [07:17<02:16, 27.34s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [07:44<01:48, 27.08s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [08:10<01:20, 26.85s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [08:37<00:53, 26.77s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [09:03<00:26, 26.71s/it]\u001b[A\n",
      "100%|██████████| 20/20 [09:30<00:00, 28.52s/it]\u001b[A\n",
      "Inference:  50%|█████     | 4/8 [34:37<37:23, 560.89s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 1/21 [00:05<01:43,  5.19s/it]\u001b[A\n",
      " 10%|▉         | 2/21 [00:10<01:38,  5.17s/it]\u001b[A\n",
      " 14%|█▍        | 3/21 [00:15<01:32,  5.13s/it]\u001b[A\n",
      " 19%|█▉        | 4/21 [00:20<01:27,  5.12s/it]\u001b[A\n",
      " 24%|██▍       | 5/21 [00:25<01:21,  5.11s/it]\u001b[A\n",
      " 29%|██▊       | 6/21 [00:31<01:18,  5.24s/it]\u001b[A\n",
      " 33%|███▎      | 7/21 [00:36<01:12,  5.18s/it]\u001b[A\n",
      " 38%|███▊      | 8/21 [00:41<01:07,  5.16s/it]\u001b[A\n",
      " 43%|████▎     | 9/21 [00:46<01:01,  5.16s/it]\u001b[A\n",
      " 48%|████▊     | 10/21 [00:51<00:56,  5.16s/it]\u001b[A\n",
      " 52%|█████▏    | 11/21 [00:56<00:51,  5.17s/it]\u001b[A\n",
      " 57%|█████▋    | 12/21 [01:02<00:46,  5.18s/it]\u001b[A\n",
      " 62%|██████▏   | 13/21 [01:07<00:42,  5.25s/it]\u001b[A\n",
      " 67%|██████▋   | 14/21 [01:12<00:36,  5.21s/it]\u001b[A\n",
      " 71%|███████▏  | 15/21 [01:17<00:31,  5.17s/it]\u001b[A\n",
      " 76%|███████▌  | 16/21 [01:22<00:25,  5.17s/it]\u001b[A\n",
      " 81%|████████  | 17/21 [01:27<00:20,  5.17s/it]\u001b[A\n",
      " 86%|████████▌ | 18/21 [01:33<00:15,  5.15s/it]\u001b[A\n",
      " 90%|█████████ | 19/21 [01:38<00:10,  5.25s/it]\u001b[A\n",
      " 95%|█████████▌| 20/21 [01:43<00:05,  5.21s/it]\u001b[A\n",
      "100%|██████████| 21/21 [01:43<00:00,  4.94s/it]\u001b[A\n",
      "Inference:  62%|██████▎   | 5/8 [36:21<19:48, 396.28s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:48<15:14, 48.14s/it]\u001b[A\n",
      " 10%|█         | 2/20 [01:32<13:46, 45.91s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [02:42<16:04, 56.75s/it]\u001b[A\n",
      " 20%|██        | 4/20 [03:26<13:50, 51.91s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [04:10<12:17, 49.18s/it]\u001b[A\n",
      " 30%|███       | 6/20 [04:55<11:06, 47.61s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [05:40<10:07, 46.76s/it]\u001b[A\n",
      " 40%|████      | 8/20 [06:25<09:14, 46.21s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [07:10<08:23, 45.77s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [07:56<07:37, 45.75s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [08:41<06:51, 45.72s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [09:27<06:05, 45.74s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [10:12<05:18, 45.55s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [10:58<04:33, 45.60s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [11:43<03:46, 45.37s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [12:47<03:23, 50.97s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [13:45<02:39, 53.27s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [14:31<01:42, 51.07s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [15:17<00:49, 49.36s/it]\u001b[A\n",
      "100%|██████████| 20/20 [16:02<00:00, 48.11s/it]\u001b[A\n",
      "Inference:  75%|███████▌  | 6/8 [52:24<19:37, 588.96s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:47<14:59, 47.32s/it]\u001b[A\n",
      " 10%|█         | 2/20 [01:39<15:04, 50.23s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [02:33<14:43, 51.95s/it]\u001b[A\n",
      " 20%|██        | 4/20 [03:20<13:19, 49.97s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [04:07<12:14, 48.98s/it]\u001b[A\n",
      " 30%|███       | 6/20 [04:59<11:36, 49.77s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [05:45<10:34, 48.77s/it]\u001b[A\n",
      " 40%|████      | 8/20 [06:32<09:37, 48.14s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [07:45<10:15, 55.93s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [08:33<08:53, 53.37s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [09:20<07:42, 51.39s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [10:06<06:39, 49.91s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [10:53<05:43, 49.06s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [11:40<04:50, 48.44s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [12:28<04:00, 48.19s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [13:16<03:12, 48.15s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [14:03<02:23, 47.78s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [14:50<01:35, 47.51s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [15:37<00:47, 47.37s/it]\u001b[A\n",
      "100%|██████████| 20/20 [16:24<00:00, 49.25s/it]\u001b[A\n",
      "Inference:  88%|████████▊ | 7/8 [1:08:50<11:58, 718.62s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:07<02:27,  7.74s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:15<02:17,  7.63s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:21<01:56,  6.83s/it]\u001b[A\n",
      " 20%|██        | 4/20 [00:27<01:43,  6.47s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [00:33<01:34,  6.32s/it]\u001b[A\n",
      " 30%|███       | 6/20 [00:39<01:27,  6.26s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [00:45<01:21,  6.27s/it]\u001b[A\n",
      " 40%|████      | 8/20 [00:51<01:13,  6.16s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [00:57<01:06,  6.07s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [01:03<00:59,  6.00s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [01:09<00:53,  5.96s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [01:18<00:56,  7.02s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [01:31<01:01,  8.82s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [01:45<01:01, 10.24s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [01:57<00:54, 10.99s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [02:04<00:39,  9.78s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [02:10<00:26,  8.69s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [02:17<00:15,  7.96s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [02:23<00:07,  7.47s/it]\u001b[A\n",
      "100%|██████████| 20/20 [02:29<00:00,  7.47s/it]\u001b[A\n",
      "Inference: 100%|██████████| 8/8 [1:11:20<00:00, 535.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "   ***  Wrote inference_layout_xla_random.csv \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "_INFERENCE_CONFIGS_BATCH_SIZE = 50\n",
    "\n",
    "output_csv_filename = f'inference_layout_{SOURCE}_{SEARCH}.csv'\n",
    "print('\\n\\n   Running inference on test set ...\\n\\n')\n",
    "test_rankings = []\n",
    "\n",
    "assert layout_npz_dataset.test.graph_id is not None\n",
    "for graph in tqdm.tqdm(layout_npz_dataset.test.iter_graph_tensors(),\n",
    "                       total=layout_npz_dataset.test.graph_id.shape[-1],\n",
    "                       desc='Inference'):\n",
    "    num_configs = graph.node_sets['g']['runtimes'].shape[-1]\n",
    "    all_scores = []\n",
    "    for i in tqdm.tqdm(range(0, num_configs, _INFERENCE_CONFIGS_BATCH_SIZE)):\n",
    "        end_i = min(i + _INFERENCE_CONFIGS_BATCH_SIZE, num_configs)\n",
    "        # Take a cut of the configs.\n",
    "        node_set_g = graph.node_sets['g']\n",
    "        subconfigs_graph = tfgnn.GraphTensor.from_pieces(\n",
    "            edge_sets=graph.edge_sets,\n",
    "            node_sets={\n",
    "                'op': graph.node_sets['op'],\n",
    "                'nconfig': tfgnn.NodeSet.from_fields(\n",
    "                    sizes=graph.node_sets['nconfig'].sizes,\n",
    "                    features={\n",
    "                        'feats': graph.node_sets['nconfig']['feats'][:, i:end_i],\n",
    "                    }),\n",
    "                'g': tfgnn.NodeSet.from_fields(\n",
    "                    sizes=tf.constant([1]),\n",
    "                    features={\n",
    "                        'graph_id': node_set_g['graph_id'],\n",
    "                        'runtimes': node_set_g['runtimes'][:, i:end_i],\n",
    "                        'kept_node_ratio': node_set_g['kept_node_ratio'],\n",
    "                    })\n",
    "            })\n",
    "        h = model.forward(subconfigs_graph, num_configs=(end_i - i),\n",
    "                          backprop=False)\n",
    "        all_scores.append(h[0])\n",
    "    all_scores = tf.concat(all_scores, axis=0)\n",
    "    graph_id = graph.node_sets['g']['graph_id'][0].numpy().decode()\n",
    "    sorted_indices = tf.strings.join(\n",
    "        tf.strings.as_string(tf.argsort(all_scores)), ';').numpy().decode()\n",
    "    test_rankings.append((graph_id, sorted_indices))\n",
    "\n",
    "with tf.io.gfile.GFile(output_csv_filename, 'w') as fout:\n",
    "    fout.write('ID,TopConfigs\\n')\n",
    "    for graph_id, ranks in test_rankings:\n",
    "        fout.write(f'layout:{SOURCE}:{SEARCH}:{graph_id},{ranks}\\n')\n",
    "print('\\n\\n   ***  Wrote', output_csv_filename, '\\n\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
